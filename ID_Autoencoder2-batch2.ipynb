{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9041b548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abf8653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    _, file_extension = os.path.splitext(filepath)\n",
    "    \n",
    "    if file_extension == '.csv':\n",
    "        df = pd.read_csv(filepath)\n",
    "        samples = df['your_column_name'].values\n",
    "    elif file_extension == '.dat':\n",
    "        with open(filepath, 'r') as f:\n",
    "            samples = f.readlines()\n",
    "        samples = np.array([sample.strip() for sample in samples])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {file_extension}\")\n",
    "    \n",
    "    return samples\n",
    "\n",
    "def count_lines(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        return sum(1 for _ in f)\n",
    "\n",
    "\n",
    "def process_data(samples):\n",
    "    real_parts = []\n",
    "    imag_parts = []\n",
    "    for sample in samples:\n",
    "        try:\n",
    "            cnum = complex(sample.replace('j', 'j'))\n",
    "            real_parts.append(np.real(cnum))\n",
    "            imag_parts.append(np.imag(cnum))\n",
    "        except ValueError:\n",
    "            #print(f\"Malformed complex number string: {sample}\")\n",
    "            continue  # error values are not important\n",
    "\n",
    "    real_parts = (real_parts - np.mean(real_parts)) / np.std(real_parts)\n",
    "    imag_parts = (imag_parts - np.mean(imag_parts)) / np.std(imag_parts)\n",
    "    \n",
    "    sequence_length = 10\n",
    "    X = [list(zip(real_parts[i:i+sequence_length], imag_parts[i:i+sequence_length])) for i in range(len(real_parts) - sequence_length)]\n",
    "    return np.array(X)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_generator(filepath, batch_size=20, max_samples=None):\n",
    "    chunksize = batch_size * sequence_length\n",
    "    _, file_extension = os.path.splitext(filepath)\n",
    "\n",
    "    total_samples_processed = 0\n",
    "\n",
    "    # I read data in chunks both csv and dat\n",
    "    if file_extension == '.csv':\n",
    "        for chunk in pd.read_csv(filepath, chunksize=chunksize):\n",
    "            if max_samples and total_samples_processed >= max_samples:\n",
    "                break\n",
    "            samples = chunk['IQ Data'].values\n",
    "            X_chunk = process_data(samples)\n",
    "            total_samples_processed += len(samples)\n",
    "            yield X_chunk\n",
    "\n",
    "    \n",
    "    elif file_extension == '.dat':\n",
    "        samples = []\n",
    "        skip_zeros = True  # flag to check if we should still skip zero lines\n",
    "        with open(filepath, 'r', errors='replace') as f:  # reading in text mode,should handle decoding\n",
    "            for line in f:\n",
    "                #print('line:', line)\n",
    "                try:\n",
    "                    #decoded_line = line.decode('utf-8').strip()\n",
    "                    decoded_line = line.strip()\n",
    "                    samples.append(decoded_line)\n",
    "                except UnicodeDecodeError:\n",
    "                    pass\n",
    "                if not line:\n",
    "                    continue\n", #don't care null lines, pass!
    "                if max_samples and total_samples_processed >= max_samples:\n",
    "                    break\n",
    "                samples.append(line)\n",
    "                total_samples_processed += 1\n",
    "                if len(samples) == chunksize:\n",
    "                    X_chunk = process_data(samples)\n",
    "                    print(\"Samples:\", samples)\n",
    "                    print(\"X_chunk:\", X_chunk)\n",
    "                    print(\"Shape of X_chunk:\", X_chunk.shape)\n",
    "                    yield X_chunk\n",
    "                    samples = []\n",
    "\n",
    "\n",
    "\n",
    "#in RNN: we should determine the number of consecutive samples grouped together as a single input \n",
    "#sequence for the RNN, so the model will take the first N samples as input \n",
    "#and try to reconstruct them.\n",
    "\n",
    "sequence_length = 10\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(sequence_length, 2), return_sequences=True))\n",
    "model.add(LSTM(25, activation='relu', return_sequences=False))\n",
    "model.add(RepeatVector(sequence_length))\n",
    "model.add(LSTM(25, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(2)))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# first I need to train pure data batch by batch\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "num_pure_samples = count_lines('/home/mreza/5G accelerator/models/5G_DL_IQ_no_jamming_0924.dat')\n",
    "print('num_pure_samples:', num_pure_samples)\n",
    "\n",
    "max_train_samples = 100000  # I limit the train or can put None for whole data\n",
    "train_steps = (min(num_pure_samples, max_train_samples) if \n",
    "               max_train_samples else num_pure_samples) // (batch_size * sequence_length)\n",
    "\n",
    "train_gen = data_generator('/home/mreza/5G accelerator/models/5G_DL_IQ_no_jamming_0924.dat', batch_size, max_train_samples)\n",
    "model.fit(train_gen, steps_per_epoch=train_steps, epochs=10, verbose=1)\n",
    "\n",
    "\n",
    "# Now reconstructing error by trained model and infected data\n",
    "combined_gen = data_generator('/home/mreza/5G accelerator/models/5G_DL_IQ_with_periodic_jamming_0928_02.dat', batch_size)\n",
    "reconstruction_errors = []\n",
    "for X_chunk_test in combined_gen:\n",
    "    X_chunk_pred = model.predict(X_chunk_test)\n",
    "    chunk_errors = np.mean(np.square(X_chunk_test - X_chunk_pred), axis=1)\n",
    "    reconstruction_errors.extend(chunk_errors)\n",
    "\n",
    "reconstruction_error = np.array(reconstruction_errors)\n",
    "\n",
    "# set threshold\n",
    "threshold = np.percentile(reconstruction_error, 95)\n",
    "\n",
    "jamming_detected = reconstruction_error > threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b7cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_jamming_detected = np.sum(jamming_detected)\n",
    "print(f\"Number of jamming sequences detected: {num_jamming_detected} out of {len(X_test)} sequences\")\n",
    "\n",
    "# reconstruction error\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(reconstruction_error, label='Reconstruction Error')\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error with Threshold')\n",
    "plt.xlabel('Sequence Number')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8867f3c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b8e60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
