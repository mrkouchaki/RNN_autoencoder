{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19732068",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 15:49:55.786715: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-06 15:49:55.787788: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-06 15:49:55.811596: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-06 15:49:55.812137: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-06 15:49:56.215803: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 50)            10600     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 25)                7600      \n",
      "                                                                 \n",
      " repeat_vector (RepeatVecto  (None, 10, 25)            0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 10, 25)            5100      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 10, 50)            15200     \n",
      "                                                                 \n",
      " time_distributed (TimeDist  (None, 10, 2)             102       \n",
      " ributed)                                                        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38602 (150.79 KB)\n",
      "Trainable params: 38602 (150.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "Step 26364/26364\n",
      "num_samples = count_lines: 5272809\n",
      "Maximum number of predictions available: 26364\n",
      "Number of predictions to be performed: 2\n",
      "prediction number: 0\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "prediction number: 1\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Reconstruction error calculated.\n",
      "Total number of samples 5273200\n",
      "threshold magnitude: 0.022580143115415157\n",
      "threshold percentile: 0.042915288940964795\n",
      "jamming_detected: [[False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False  True]\n",
      " [ True False]\n",
      " [ True False]\n",
      " [ True  True]\n",
      " [False  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [False  True]\n",
      " [False  True]\n",
      " [False False]\n",
      " [False  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True False]\n",
      " [False False]\n",
      " [False  True]\n",
      " [ True  True]\n",
      " [False False]\n",
      " [False  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [False False]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True False]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [False  True]\n",
      " [False False]\n",
      " [False False]\n",
      " [False  True]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False  True]\n",
      " [False False]\n",
      " [False False]\n",
      " [ True  True]\n",
      " [False False]\n",
      " [False False]\n",
      " [ True  True]\n",
      " [False  True]\n",
      " [ True  True]\n",
      " [False False]\n",
      " [False False]\n",
      " [False  True]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False  True]\n",
      " [False False]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True False]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True  True]\n",
      " [ True False]\n",
      " [ True  True]\n",
      " [False  True]\n",
      " [ True  True]\n",
      " [ True False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]\n",
      " [False False]]\n",
      "        Part  True Count  False Count\n",
      "0       Real          43          337\n",
      "1  Imaginary          50          330\n",
      "2    Overall          93          667\n",
      "Number of jamming sequences detected: 93 out of 760 sequences\n",
      "Shape of avg_real: (190,)\n",
      "Shape of avg_imag: (190,)\n",
      "Shape of last_errors: 190\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, RepeatVector, TimeDistributed, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import struct\n",
    "\n",
    "totalMagnitude = 0\n",
    "totalnumberofsamples = 0\n",
    "def load_data(filepath):\n",
    "    _, file_extension = os.path.splitext(filepath)\n",
    "    \n",
    "    if file_extension == '.csv':\n",
    "        df = pd.read_csv(filepath)\n",
    "        samples = df['your_column_name'].values\n",
    "    elif file_extension == '.dat':\n",
    "        #Looks like DAT is binary encoded added a b in r as rb\n",
    "        with open(filepath, 'rb') as f:\n",
    "            samples = f.readlines()\n",
    "        samples = np.array([sample.strip() for sample in samples])\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {file_extension}\")\n",
    "    \n",
    "    return samples\n",
    "\n",
    "def count_lines(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        return sum(1 for _ in f)\n",
    "\n",
    "\n",
    "class DataGenerator:        \n",
    "    def __init__(self, filepath, batch_size, sequence_length, max_samples=None, for_training=True):\n",
    "        self.filepath = filepath\n",
    "        self.batch_size = batch_size\n",
    "        self.sequence_length = sequence_length\n",
    "        self.max_samples = max_samples\n",
    "        self.for_training = for_training\n",
    "        self.samples = []\n",
    "        self.binary_file = open(self.filepath, 'rb')  # Initialize the binary_file here\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.total_samples_processed = 0\n",
    "        _, self.file_extension = os.path.splitext(self.filepath)\n",
    "\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.binary_file.seek(0)  # reset file pointer\n",
    "        self.samples = []\n",
    "        return self\n",
    "    \n",
    "    def close(self):\n",
    "        if not self.binary_file.closed:\n",
    "            self.binary_file.close()\n",
    "\n",
    "    def process_data(self, samples):\n",
    "        real_parts = []\n",
    "        imag_parts = []\n",
    "        for sample in samples:\n",
    "            try:\n",
    "                cnum = complex(sample.replace('j', 'j'))\n",
    "                real_parts.append(np.real(cnum))\n",
    "                imag_parts.append(np.imag(cnum))\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        real_parts = (real_parts - np.mean(real_parts)) / np.std(real_parts)\n",
    "        imag_parts = (imag_parts - np.mean(imag_parts)) / np.std(imag_parts)\n",
    "\n",
    "        X = [list(zip(real_parts[i:i+self.sequence_length], imag_parts[i:i+self.sequence_length])) for i in range(len(real_parts) - self.sequence_length)]\n",
    "        return np.array(X)\n",
    "\n",
    "    def __next__(self):\n",
    "        chunksize = self.batch_size * self.sequence_length\n",
    "        global totalMagnitude  # Access the global variable\n",
    "        global totalnumberofsamples  # Access the global variable\n",
    "        \n",
    "        if self.file_extension == '.dat':\n",
    "            samples = []\n",
    "            while True:\n",
    "                binary_data = self.binary_file.read(8)\n",
    "                if not binary_data:\n",
    "                    break \n",
    "                decoded_data = struct.unpack('ff', binary_data)\n",
    "                if decoded_data[0] == 0 and decoded_data[1] == 0:\n",
    "                    decoded_line = f\"0j\\n\"\n",
    "                    #Calculates the mangitude of the complex number\n",
    "                    totalMagnitude += abs(complex(decoded_line)) \n",
    "                    totalnumberofsamples +=1\n",
    "                else:\n",
    "                    if decoded_data[1] >= 0:\n",
    "                        decoded_line = f\"{decoded_data[0]}+{decoded_data[1]}j\\n\"\n",
    "                        #Calculates the mangitude of the complex number\n",
    "                        totalMagnitude += abs(complex(decoded_line)) \n",
    "                        totalnumberofsamples +=1                        \n",
    "                    else:\n",
    "                        decoded_line = f\"{decoded_data[0]}{decoded_data[1]}j\\n\"\n",
    "                        #Calculates the mangitude of the complex number\n",
    "                        totalMagnitude += abs(complex(decoded_line)) \n",
    "                        totalnumberofsamples +=1                       \n",
    "                samples.append(decoded_line)\n",
    "\n",
    "                if self.max_samples and self.total_samples_processed >= self.max_samples:\n",
    "                    raise StopIteration\n",
    "                self.total_samples_processed += 1\n",
    "                #print('samples:', samples)\n",
    "                if len(samples) == chunksize:\n",
    "                    X_chunk = self.process_data(samples)\n",
    "                    #print('X_chunk:', X_chunk)\n",
    "                    if self.for_training:\n",
    "                        return X_chunk, X_chunk\n",
    "                    else:\n",
    "                        return X_chunk\n",
    "                    samples = []\n",
    "\n",
    "        \n",
    "        else:\n",
    "            raise StopIteration\n",
    "\n",
    "\n",
    "#in RNN: we should determine the number of consecutive samples grouped together as a single input \n",
    "#sequence for the RNN, so the model will take the first N samples as input \n",
    "#and try to reconstruct them.\n",
    "\n",
    "sequence_length = 10\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(sequence_length, 2), return_sequences=True))\n",
    "model.add(LSTM(25, activation='relu', return_sequences=False))\n",
    "model.add(RepeatVector(sequence_length))\n",
    "model.add(LSTM(25, activation='relu', return_sequences=True))\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(2)))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# first I need to train pure data batch by batch\n",
    "\n",
    "batch_size = 20\n",
    "num_pure_samples = count_lines('/home/mreza/5G accelerator/models/5G_DL_IQ_no_jamming_0924.dat')\n",
    "#print('num_pure_samples:', num_pure_samples)\n",
    "\n",
    "max_train_samples = None  # I limit the train or can put None for whole data\n",
    "train_steps = (min(num_pure_samples, max_train_samples) if \n",
    "               max_train_samples else num_pure_samples) // (batch_size * sequence_length)\n",
    "\n",
    "\n",
    "train_gen_instance = DataGenerator('/home/mreza/5G accelerator/models/5G_DL_IQ_no_jamming_0924.dat', \n",
    "                                   batch_size=batch_size, sequence_length=sequence_length, \n",
    "                                   max_samples=max_train_samples, for_training=True)\n",
    "\n",
    "# Modify training loop\n",
    "num_epochs = 1  # You can adjust the number of epochs as needed\n",
    "steps_per_epoch = train_steps  # Assuming one epoch processes all the data\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    train_gen_instance.reset()  # Reset the generator at the beginning of each epoch\n",
    "    for step in range(steps_per_epoch):\n",
    "        try:\n",
    "            X_chunk, Y_chunk = next(train_gen_instance)\n",
    "        except StopIteration:\n",
    "            train_gen_instance.reset()  # Reset the generator when it runs out of data\n",
    "            X_chunk, Y_chunk = next(train_gen_instance)\n",
    "\n",
    "        model.train_on_batch(X_chunk, Y_chunk)\n",
    "        print(f\"Step {step + 1}/{steps_per_epoch}\", end='\\r')\n",
    "    print()\n",
    "combined_gen_instance = DataGenerator('/home/mreza/5G accelerator/models/5G_DL_IQ_with_periodic_jamming_0928_02.dat', \n",
    "                                      batch_size=batch_size, sequence_length=sequence_length, \n",
    "                                      for_training=False)\n",
    "\n",
    "\n",
    "num_samples = count_lines('/home/mreza/5G accelerator/models/5G_DL_IQ_no_jamming_0924.dat')\n",
    "print('num_samples = count_lines:', num_samples)\n",
    "max_predictions = num_samples // (batch_size * sequence_length)\n",
    "\n",
    "#3500\n",
    "num_predictions = 2  # or any other large number\n",
    "num_predictions = min(num_predictions, max_predictions)\n",
    "\n",
    "print(f\"Maximum number of predictions available: {max_predictions}\")\n",
    "print(f\"Number of predictions to be performed: {num_predictions}\")\n",
    "\n",
    "reconstruction_errors = []\n",
    "try:\n",
    "    for _ in range(num_predictions):\n",
    "        print('prediction number:', _)\n",
    "        X_chunk_test = next(combined_gen_instance)\n",
    "        X_chunk_pred = model.predict(X_chunk_test)\n",
    "        chunk_errors = np.mean(np.square(X_chunk_test - X_chunk_pred), axis=1)\n",
    "        reconstruction_errors.extend(chunk_errors)\n",
    "except StopIteration:\n",
    "    print(\"All samples processed.\")\n",
    "    \n",
    "    \n",
    "reconstruction_error = np.array(reconstruction_errors)\n",
    "print(\"Reconstruction error calculated.\")\n",
    "\n",
    "# set threshold\n",
    "#threshold = np.percentile(reconstruction_error, 95)\n",
    "threshold =totalMagnitude /totalnumberofsamples\n",
    "print(\"Total number of samples\", totalnumberofsamples)\n",
    "print('threshold magnitude:', threshold)\n",
    "print('threshold percentile:', np.percentile(reconstruction_error, 95))\n",
    "\n",
    "jamming_detected = reconstruction_error > threshold\n",
    "print('jamming_detected:', jamming_detected)\n",
    "\n",
    "train_gen_instance.close()\n",
    "combined_gen_instance.close()\n",
    "\n",
    "\n",
    "\n",
    "### visualization #######\n",
    "#Table to get insight\n",
    "flattened_jamming_detected = jamming_detected.flatten()\n",
    "\n",
    "real_part_detected = jamming_detected[:, 0]\n",
    "imag_part_detected = jamming_detected[:, 1]\n",
    "\n",
    "real_true_count = np.sum(real_part_detected)\n",
    "real_false_count = len(real_part_detected) - real_true_count\n",
    "\n",
    "imag_true_count = np.sum(imag_part_detected)\n",
    "imag_false_count = len(imag_part_detected) - imag_true_count\n",
    "\n",
    "# Overall\n",
    "overall_true_count = np.sum(flattened_jamming_detected)\n",
    "overall_false_count = len(flattened_jamming_detected) - overall_true_count\n",
    "\n",
    "# Table-DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Part': ['Real', 'Imaginary', 'Overall'],\n",
    "    'True Count': [real_true_count, imag_true_count, overall_true_count],\n",
    "    'False Count': [real_false_count, imag_false_count, overall_false_count]\n",
    "})\n",
    "\n",
    "print(df)\n",
    "\n",
    "num_jamming_detected = np.sum(jamming_detected)\n",
    "print(f\"Number of jamming sequences detected: {num_jamming_detected} out of {len(flattened_jamming_detected)} sequences\")\n",
    "\n",
    "\n",
    "# reconstruction error\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(reconstruction_error, label='Reconstruction Error')\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error with Threshold')\n",
    "plt.xlabel('Sequence Number')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "plt.savefig('1-Reconstruction Error with Threshold.png')\n",
    "plt.close()\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# reconstruction error\n",
    "reconstruction_error_real = reconstruction_error[:, 0]\n",
    "reconstruction_error_imag = reconstruction_error[:, 1]\n",
    "\n",
    "# Plot for Real Part\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(reconstruction_error_real, label='Reconstruction Error - Real Part', color='blue')\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error for Real Part with Threshold')\n",
    "plt.xlabel('Sequence Number')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "plt.savefig('2-Reconstruction Error for Real Part with Threshold.png')\n",
    "plt.close()\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "# Plot for Imaginary Part\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(reconstruction_error_imag, label='Reconstruction Error - Imaginary Part', color='orange')\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error for Imaginary Part with Threshold')\n",
    "plt.xlabel('Sequence Number')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "plt.savefig('3-Reconstruction Error for Imaginary Part with Threshold.png')\n",
    "plt.close()\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#Histogram of Reconstruction Errors:\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.hist(reconstruction_error, bins=50, alpha=0.75)\n",
    "plt.axvline(x=threshold, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Histogram of Reconstruction Errors')\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.savefig('4-Histogram of Reconstruction Errors.png')\n",
    "plt.close()\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "#Time Series Plot of IQ Samples:\n",
    "sample_index = np.random.choice(len(X_chunk_test))\n",
    "original_sample = X_chunk_test[sample_index]\n",
    "reconstructed_sample = X_chunk_pred[sample_index]\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample[:, 1], 'g-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 1], 'y--', label='Reconstructed Imaginary Part')\n",
    "plt.title('Original vs Reconstructed IQ Data for a Random Sample')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.savefig('5-Original vs Reconstructed IQ Data for a Random Sample.png')\n",
    "plt.close()\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#Scatter Plot of Reconstruction Errors vs. Real and Imaginary Parts:\n",
    "avg_real = np.mean(X_chunk_test, axis=1)[:, 0]\n",
    "avg_imag = np.mean(X_chunk_test, axis=1)[:, 1]\n",
    "\n",
    "last_errors = np.mean(reconstruction_errors[-len(X_chunk_test):], axis=1)\n",
    "\n",
    "print(\"Shape of avg_real:\", avg_real.shape)\n",
    "print(\"Shape of avg_imag:\", avg_imag.shape)\n",
    "print(\"Shape of last_errors:\", len(last_errors))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.scatter(avg_real, last_errors, label='Real Part', alpha=0.5)\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error vs. Average Real Part')\n",
    "plt.xlabel('Average Amplitude')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "plt.savefig('6-Reconstruction Error vs. Average Real Part.png')\n",
    "plt.close()\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.scatter(avg_imag, last_errors, label='Imaginary Part', alpha=0.5)\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold')\n",
    "plt.title('Reconstruction Error vs. Average Imaginary Part')\n",
    "plt.xlabel('Average Amplitude')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.legend()\n",
    "plt.savefig('7-Reconstruction Error vs. Average Imaginary Part.png')\n",
    "plt.close()\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the number of sequences to plot together\n",
    "n = 5  # change this to desired number of sequences\n",
    "sample_length = sequence_length * n\n",
    "\n",
    "# Select a random sample for plotting\n",
    "sample_index = np.random.choice(len(X_chunk_test) - sample_length + 1)\n",
    "\n",
    "# Extract the original and reconstructed samples\n",
    "original_sample = X_chunk_test[sample_index:sample_index + sample_length]\n",
    "reconstructed_sample = X_chunk_pred[sample_index:sample_index + sample_length]\n",
    "\n",
    "# Plot concatenated sequences\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample[:, 1], 'g-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 1], 'y--', label='Reconstructed Imaginary Part')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.savefig('8-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "plt.close()\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "# Define the number of sequences to plot together\n",
    "n = 9  # You can change this to the desired number of sequences\n",
    "sample_length = sequence_length * n\n",
    "\n",
    "# Select a random sample for plotting\n",
    "sample_index = np.random.choice(len(X_chunk_test) - sample_length + 1)\n",
    "\n",
    "# Extract the original and reconstructed samples\n",
    "original_sample = X_chunk_test[sample_index:sample_index + sample_length]\n",
    "reconstructed_sample = X_chunk_pred[sample_index:sample_index + sample_length]\n",
    "\n",
    "# Plot the concatenated sequences\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(original_sample[:, 0], 'b-', label='Original Real Part')\n",
    "plt.plot(reconstructed_sample[:, 0], 'r--', label='Reconstructed Real Part')\n",
    "plt.plot(original_sample[:, 1], 'g-', label='Original Imaginary Part')\n",
    "plt.plot(reconstructed_sample[:, 1], 'y--', label='Reconstructed Imaginary Part')\n",
    "plt.title(f'Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.savefig('9-Original vs Reconstructed IQ Data for {n} Sequences of Length {sequence_length}.png')\n",
    "plt.close()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
